@misc{hayes2008online,
abstract = {Several techniques are currently used to evaluate recommender&#xD;&#xA;systems. These techniques involve off-line analysis using evaluation&#xD;&#xA;methods from machine learning and information retrieval. We&#xD;&#xA;argue that while off-line analysis is useful, user satisfaction with a recommendation&#xD;&#xA;strategy can only be measured in an on-line context. We&#xD;&#xA;propose a new evaluation framework which involves a paired test of two&#xD;&#xA;recommender systems which simultaneously compete to give the best&#xD;&#xA;recommendations to the same user at the same time. The user interface&#xD;&#xA;and the interaction model for each system is the same. The framework&#xD;&#xA;enables you to specify an API so that different recommendation strategies&#xD;&#xA;may take part in such a competition. The API defines issues such as&#xD;&#xA;access to data, the interaction model and the means of gathering positive&#xD;&#xA;feedback from the user. In this way it is possible to obtain a relative&#xD;&#xA;measure of user satisfaction with the two systems.},
id = {TCD-CS-2002-19, https://www.cs.tcd.ie/publications/tech-reports/reports.02/TCD-CS-2002-19.pdf, http://hdl.handle.net/2262/13178},
author = {Hayes, Conor and Cunningham, Padraig},
title = {An on-line evaluation framework for recommender systems},
year = {2008},
type = {Technical Report},
publisher = {Trinity College Dublin, Department of Computer Science}
,url = {http://www.tara.tcd.ie/handle/2262/13178?mode=full&submit_simple=Show+full+item+record}
}