@incollection{springerlink:10.1007/3-540-34416-0_27,
   author = {Grčar, Miha and Fortuna, Blaž and Mladenič, Dunja and Grobelnik, Marko},
   affiliation = {Jožef Stefan Institute Jamova 39 SI-1000 Ljubljana Slovenia},
   title = {kNN Versus SVM in the Collaborative Filtering Framework},
   booktitle = {Data Science and Classification},
   series = {Studies in Classification, Data Analysis, and Knowledge Organization},
   editor = {Batagelj, Vladimir and Bock, Hans-Hermann and Ferligoj, Anuška and Žiberna, Aleš},
   publisher = {Springer},
   address = {Berlin Heidelberg},
   isbn = {978-3-540-34416-2},
   keyword = {Statistics},
   pages = {251-260},
   url = {http://dx.doi.org/10.1007/3-540-34416-0_27},
   doi = {10.1007/3-540-34416-0_27},
   abstract = {We present experimental results of confronting the k-Nearest Neighbor (kNN) algorithm with Support Vector Machine (SVM) in the collaborative filtering framework using datasets with different properties. While k-Nearest Neighbor is usually used for the collaborative filtering tasks, Support Vector Machine is considered a state-of-the-art classification algorithm. Since collaborative filtering can also be interpreted as a classification/regression task, virtually any supervised learning algorithm (such as SVM) can also be applied. Experiments were performed on two standard, publicly available datasets and, on the other hand, on a real-life corporate dataset that does not fit the profile of ideal data for collaborative filtering. We conclude that the quality of collaborative filtering recommendations is highly dependent on the quality of the data. Furthermore, we can see that kNN is dominant over SVM on the two standard datasets. On the real-life corporate dataset with high level of sparsity, kNN fails as it is unable to form reliable neighborhoods. In this case SVM outperforms kNN.},
   year = {2006}
}
