@article {Palminteri090654,
	author = {Palminteri, Stefano and Lefebvre, Germain and Kilford, Emma J and Blakemore, Sarah-Jayne},
	title = {Confirmation bias in human reinforcement learning: evidence from counterfactual feedback processing},
	year = {2016},
	doi = {10.1101/090654},
	publisher = {Cold Spring Harbor Labs Journals},
	abstract = {Previous studies suggest that factual learning, that is learning from obtained outcomes, is biased, such that participants preferentially take into account positive, as compared to negative, prediction errors. However, whether or not the prediction error valence also affects counterfactual learning, that is, learning from forgone outcomes, is unknown. To address this question, we analysed the performance of two cohorts of participants on reinforcement learning tasks using a computational model that was adapted to test if prediction error valance influences learning. Concerning factual learning, we replicated previous findings of a valence-induced bias, whereby participants learned preferentially from positive, relative to negative, prediction errors. In contrast, for counterfactual learning, we found the opposite valence-induced bias: negative prediction errors were preferentially taken into account relative to positive ones. When considering valence-induced bias in the context of both factual and counterfactual learning, it appears that people tend to preferentially take into account information that confirms their current choice. By documenting these valence-induced learning biases, our findings demonstrate the presence of a confirmation bias in human reinforcement learning.},
	URL = {http://biorxiv.org/content/early/2016/11/30/090654},
	eprint = {http://biorxiv.org/content/early/2016/11/30/090654.full.pdf},
	journal = {bioRxiv}
}
